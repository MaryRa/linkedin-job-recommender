{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40b6040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import langid\n",
    "from random import shuffle\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import display\n",
    "from contextlib import contextmanager\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69344a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/config.yaml\") as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "filename = cfg['vacancy-file']\n",
    "filename_out = cfg['vacancy-train-file']\n",
    "\n",
    "if filename in os.listdir('.'):\n",
    "    df = pd.read_csv(filename, index_col=0)\n",
    "else:\n",
    "    raise Exception(f'There is no file {filename}, run \"1. linkedin jobs miners.ipynb\" first')\n",
    "    sys.exit()\n",
    "\n",
    "df = df[~df['text'].isna()].drop_duplicates().reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354ef999",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['language'] == 'en'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba446d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['salary_min'] = df['salary'].str.split('-').str[0].map(lambda x: ''.join(re.findall('\\d+', str(x).split(',')[0])))\n",
    "df.loc[df['salary'].isna(), 'salary_min'] = np.nan\n",
    "df['salary_min'] = df['salary_min'].astype(float)\n",
    "df['salary_max'] = df['salary'].str.split('-').str[1].map(lambda x: ''.join(re.findall('\\d+', str(x).split(',')[0])))\n",
    "df.loc[df['salary'].isna(), 'salary_max'] = np.nan\n",
    "df['salary_max'] = df['salary_max'].astype(float)\n",
    "\n",
    "df['salary_currency'] = df['salary'].str.split('-').str[0].map(\n",
    "    lambda x: ''.join(re.findall('[^(0-9,. )]', str(x).lower()))).replace('nan', '')\n",
    "\n",
    "currency_translation = {'':1, 'gbp': 1, 'usd': 0.79, 'sgd': 0.58, \n",
    "                        'jpy': 0.0055, 'mxn': 0.046, 'sek': 0.072, \n",
    "                        'eur': 0.86, 'cad': 0.59, 'aud': 0.52}\n",
    "currency_to_add = set(df['salary_currency']) - set(currency_translation.keys())\n",
    "if len(currency_to_add):\n",
    "    print(currency_to_add)\n",
    "df['salary_max_gbp'] = df['salary_currency'].map(currency_translation) * df['salary_max']\n",
    "df['salary_min_gbp'] = df['salary_currency'].map(currency_translation) * df['salary_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2ee69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df[~df['salary'].isna()]['salary_min_gbp'], bins=20)\n",
    "plt.xticks(rotation=45);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec38f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['salary_currency'][df['salary_currency'] != '']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5615de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tf_idf = TfidfVectorizer(stop_words='english', max_df=0.99, min_df=0.01, norm='l1')\n",
    "transformed_text = tf_idf.fit_transform(df['text'])\n",
    "\n",
    "tsne = TSNE(init=\"random\")\n",
    "tsne_components = tsne.fit_transform(transformed_text)\n",
    "_, ax = plt.subplots(figsize=(10,10))\n",
    "ax.scatter(x=tsne_components[:, 0], y=tsne_components[:, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5404d1",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14f8744",
   "metadata": {},
   "outputs": [],
   "source": [
    "if filename_out in os.listdir('.'):\n",
    "    train = pd.read_csv(filename_out, index_col=0).reset_index(drop=True)\n",
    "    df = df[df.columns.difference(['dont_show', 'good', 'synthetic'])]\n",
    "    df = df.merge(train.loc[~((~train['synthetic'].isna()) & (train['synthetic'])), \n",
    "                            ['title','company_name','location','date', 'dont_show', 'good', 'synthetic']], \n",
    "                  on=['title','company_name','location','date'], how='left')\n",
    "    for col in set(df.columns) - set(train.columns):\n",
    "        train[col] = np.nan\n",
    "    df = pd.concat([df, train.loc[(~train['synthetic'].isna()) & (train['synthetic']), df.columns]])\n",
    "    df = df.reset_index(drop=True)\n",
    "else:\n",
    "    df['dont_show'] = np.nan\n",
    "    df['synthetic'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7acb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(df, tf_idf):\n",
    "    model = LogisticRegression(penalty='l2', solver='liblinear') #RandomForestClassifier()\n",
    "    if ('good' in df.columns and \n",
    "        df['good'].dropna().unique().shape[0] > 1 and\n",
    "        df['good'].dropna().shape[0] >= 20):\n",
    "        \n",
    "        base_val = df['good'].isna().sum()\n",
    "        # I want to highlight synthetic class since there we will see the pure 1 or 0 class\n",
    "        # a bit less highlight vacancies which was scored and the lowest score for vacancies which were not scored yet\n",
    "        classes = ((df['good']+1).fillna(0) + df['synthetic'].fillna(0)*2).astype(int)\n",
    "        dict_coefs = {\n",
    "            0: base_val,   #they haven't scored yet\n",
    "            1: base_val, #scored as 0 and real job\n",
    "            2: base_val,  #scored as 1 and real job\n",
    "            3: base_val*2, #scored as 0 and synthetic\n",
    "            4: base_val*2  #scored as 1 and synthetic\n",
    "        }\n",
    "        dict_coefs = {x: dict_coefs[x] for x in dict_coefs if x in classes.unique()}\n",
    "        ros = RandomOverSampler(random_state=0, sampling_strategy=dict_coefs)\n",
    "        train, _ = ros.fit_resample(df, classes)\n",
    "        \n",
    "        train['good'] = train['good'].fillna(0)\n",
    "        model.fit(tf_idf.transform(train['text']), train['good'].astype(int))\n",
    "        \n",
    "        y_pred_ = model.predict_proba(tf_idf.transform(df['text']))[:, 1]\n",
    "        metric_message = f'ROC-AUC (all): {roc_auc_score(df[\"good\"].fillna(0), y_pred_):.2f}'\n",
    "        \n",
    "        true_val = df[~df['good'].isna()]\n",
    "        if true_val['good'].unique().shape[0] > 1:\n",
    "            y_pred_true = model.predict_proba(tf_idf.transform(true_val[\"text\"]))[:, 1]\n",
    "            metric_message += f', (true): {roc_auc_score(true_val[\"good\"], y_pred_true):.2f}'\n",
    "    else:\n",
    "        metric_message = \"\"\"------There is not enough data for modelling, you should review at least 20 vacancies at first  and some of them should have positive feedback----------\n",
    "It's important to use 'good staff' and 'bad stuff' space in the vacancies to highlight what would be interesting for you \n",
    "and what would not be. It can help model to select the best option for you. It can be something copy-pasted\n",
    "from the vacancy description or write in your own language. It can be also something not from vacany description, \n",
    "but you want to add to train data to improve it's preformance. \n",
    "For example, in vacancy 'R developer' you can put in 'good stuff': Python if it's important for you to see more options with Python\n",
    "\"\"\"\n",
    "        vals = min(200, df['text'].shape[0])\n",
    "        model.fit(tf_idf.transform(df['text'].head(vals)), [0] * (vals-1) + [1])\n",
    "    print(metric_message)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62130f61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(stop_words='english', max_df=0.99, min_df=0.01, norm='l1', ngram_range=(1,3))\n",
    "tf_idf.fit(df['title'] + '\\n' + df['text'])\n",
    "model = get_model(df, tf_idf)\n",
    "\n",
    "accordion = None\n",
    "indexes = None\n",
    "outs = widgets.Output()\n",
    "i = 0\n",
    "\n",
    "\n",
    "def calculate_palette(tf_idf, model):\n",
    "    names = tf_idf.get_feature_names_out()\n",
    "    result = pd.DataFrame([names, model.coef_[0]]).T\n",
    "    result.columns=['names', 'feature_importance']\n",
    "    result = result[abs(result['feature_importance'])>=abs(result['feature_importance']).sort_values().iloc[-30]]\n",
    "    cmap = sns.diverging_palette(20, 200, s=60, as_cmap=True)\n",
    "    norm = plt.Normalize(vmin=result['feature_importance'].min(), \n",
    "                         vmax=result['feature_importance'].max())\n",
    "    palette = {z: cmap(norm(h)) for h, z in zip(result['feature_importance'],result['names'])}\n",
    "    return palette\n",
    "\n",
    "def highlight_words(text, palette, pattern='(?u)\\\\b\\\\w\\\\w+\\\\b'):\n",
    "    key_words = [x for x in re.findall(pattern, text) if x.lower() in palette.keys()]\n",
    "    res = text\n",
    "    for w in key_words:\n",
    "        res = res.replace(w, \n",
    "                          f'<span style=\"background-color: rgba({palette[w.lower()][0]*255},{palette[w.lower()][1]*255},{palette[w.lower()][2]*255},1);\">{w}</span>')\n",
    "    return res\n",
    "\n",
    "def get_location(df):\n",
    "    locations = df['location'].dropna().drop_duplicates()\n",
    "    for i in np.arange(int(locations.str.split(',').str.len().max()-1), 0, step=-1):\n",
    "        locations = pd.concat([locations[locations.str.split(',').str.len() > i\n",
    "                                       ].str.split(',').str[-i:].str.join(',').drop_duplicates(), \n",
    "                               locations])\n",
    "    return locations.str.strip().unique()\n",
    "\n",
    "\n",
    "def get_widget_panel(df, i, palette=None):\n",
    "    text = ('<pre>\\n\\n</pre><b>' + df[\"title\"][i] + '</b>'+ \n",
    "            (('<pre>\\n' + df[\"salary\"][i] + '</pre>') if df[\"salary\"][i] is not np.nan else '') + \n",
    "            '<pre>\\n\\n' + df['text'][i] + '\\n\\n</pre>')\n",
    "    if palette is not None:\n",
    "        text = highlight_words(text, palette=palette)\n",
    "        \n",
    "    vacancy = widgets.HTML(\n",
    "        value = f'<a href=\"{df[\"link\"][i]}\" target=\"_blank\">link to the vacancy</a>' + text,\n",
    "        placeholder='',\n",
    "        description='',\n",
    "    )\n",
    "\n",
    "    good_bad = widgets.Dropdown(\n",
    "        options=['good', 'bad'],\n",
    "        value=None,\n",
    "        rows=3,\n",
    "        description='Good or bad?',\n",
    "        disabled=False\n",
    "    )\n",
    "    why_good = widgets.Textarea(\n",
    "        placeholder='Type something',\n",
    "        description='good stuff',\n",
    "        disabled=False,\n",
    "        layout = widgets.Layout(width='920px', height='100px')\n",
    "\n",
    "    )\n",
    "    why_bad = widgets.Textarea(\n",
    "        placeholder='Type something',\n",
    "        description='bad stuff',\n",
    "        disabled=False,\n",
    "        layout = widgets.Layout(width='920px', height='100px')\n",
    "\n",
    "    )\n",
    "    show = widgets.Checkbox(\n",
    "        value=False,\n",
    "        description=\"Don't show it again (use only when you don't want to score)\",\n",
    "        disabled=False,\n",
    "        indent=False,\n",
    "        layout = widgets.Layout(width='920px', height='30px')\n",
    "    )\n",
    "    \n",
    "    widg = widgets.VBox([vacancy, good_bad, why_good, why_bad, show])\n",
    "    return widg\n",
    "\n",
    "\n",
    "def get_filtered_df(df):\n",
    "    return df[df['dont_show'].isna() & df['synthetic'].isna()]\n",
    "\n",
    "\n",
    "def get_relevant_df(df):\n",
    "    df_filt = get_filtered_df(df)\n",
    "    if filters.children[0].children[2].value:\n",
    "        df_filt = df_filt[df_filt['date'] >= str(filters.children[0].children[2].value)]\n",
    "        \n",
    "    if filters.children[1].children[0].value and filters.children[1].children[0].value != 'All':\n",
    "        df_filt = df_filt[df_filt['title'].str.lower().str.find(filters.children[1].children[0].value.lower()) != -1]\n",
    "    if filters.children[1].children[1].value and filters.children[1].children[1].value != 'All':\n",
    "        df_filt = df_filt[df_filt['location'].str.lower().str.find(filters.children[1].children[1].value.lower()) != -1]\n",
    "    if filters.children[1].children[2].value and filters.children[1].children[2].value != 'All':\n",
    "        df_filt = df_filt[df_filt['company_name'] == filters.children[1].children[2].value]\n",
    "    if filters.children[2].children[1].value != 0:\n",
    "        df_filt = df_filt[df_filt['salary_max_gbp'] >= filters.children[2].children[1].value]\n",
    "        \n",
    "    if filters.children[2].children[0].value != '':\n",
    "        words = [x.strip() for x in (filters.children[2].children[0].value).lower().split(';')]\n",
    "        ind = False\n",
    "        for w in words:\n",
    "            ind = ind | df_filt['text'].str.lower().str.find(w) != -1\n",
    "        df_filt = df_filt[ind]\n",
    "        \n",
    "    if df_filt.shape[0] == 0:\n",
    "        return [], widgets.Accordion(children=[], selected_index=None)\n",
    "    return df_filt\n",
    "\n",
    "def refresh_indexes(df):\n",
    "    df_filt = get_relevant_df(df)\n",
    "    if filters.children[0].children[1].value == 'model_score':\n",
    "        indexes = df_filt['model_scores'].sort_values(ascending=False).index\n",
    "    elif filters.children[0].children[1].value == 'random':\n",
    "        indexes = np.array(df_filt.index)\n",
    "        shuffle(indexes)\n",
    "    elif filters.children[0].children[1].value == 'date':\n",
    "        indexes = df_filt['date'].sort_values(ascending=False).index\n",
    "    elif filters.children[0].children[1].value == 'location':\n",
    "        indexes = df_filt['location'].sort_values().index\n",
    "    elif filters.children[0].children[1].value == 'title':\n",
    "        indexes = df_filt['title'].sort_values().index\n",
    "    elif filters.children[0].children[1].value == 'salary':\n",
    "        indexes = df_filt.sort_values('salary_max_gbp', ascending=False).index\n",
    "    return indexes\n",
    "    \n",
    "def get_accordion(indexes, from_ind, to_ind):\n",
    "    palette = None\n",
    "    inds = indexes[from_ind:to_ind]\n",
    "    if filters.children[2].children[2].value:\n",
    "        palette = calculate_palette(tf_idf, model)\n",
    "    accordion = widgets.Accordion(children=[get_widget_panel(df, ind, palette) for ind in inds], selected_index=None)\n",
    "    for k, ind in enumerate(inds):\n",
    "        accordion.set_title(k, str(df.loc[ind, 'title']) + '        ---   ' +\n",
    "                            str(df.loc[ind, 'company_name']) + ' --- ' +\n",
    "                            str(df.loc[ind, 'location']) + ' --- ' +\n",
    "                            str(df.loc[ind, 'date']) + \n",
    "                            f\" (model_score={df.loc[ind, 'model_scores']:.2f})\"\n",
    "                           )\n",
    "    return accordion\n",
    "\n",
    "def show_data(refresh, from_ind, to_ind, top):\n",
    "    global indexes\n",
    "    global accordion\n",
    "    global df\n",
    "    if accordion:\n",
    "        if refresh:\n",
    "            inds = indexes[from_ind:to_ind]\n",
    "        else:\n",
    "            inds = indexes[(from_ind-top):(to_ind-top)]\n",
    "        for k, ind in enumerate(inds):\n",
    "            if accordion.children[k].children[4].value:\n",
    "                df.loc[ind, 'dont_show'] = accordion.children[k].children[4].value\n",
    "            if accordion.children[k].children[1].value is not None:\n",
    "                df.loc[ind, 'good'] = (accordion.children[k].children[1].value == 'good') * 1\n",
    "                df.loc[ind, 'dont_show'] = True\n",
    "            for is_good, text_highlight in enumerate([\n",
    "                accordion.children[k].children[3].value, \n",
    "                accordion.children[k].children[2].value]):\n",
    "                if text_highlight != '':\n",
    "                    max_ind = int(df.index.max() + 1)\n",
    "                    df.loc[max_ind, :] = df.loc[ind, :]\n",
    "                    df.loc[max_ind, 'text'] = text_highlight\n",
    "                    df.loc[max_ind, 'synthetic'] = True\n",
    "                    df.loc[max_ind, 'date'] = str(datetime.datetime.now().date())\n",
    "                    df.loc[max_ind, 'good'] = is_good\n",
    "                    df.loc[ind, 'dont_show'] = True\n",
    "                df[(~df['good'].isna()) | (~df['dont_show'].isna())].reset_index(drop=True).to_csv(filename_out)\n",
    "    \n",
    "    with outs:\n",
    "        clear_output()\n",
    "        if refresh:\n",
    "            indexes = refresh_indexes(df)\n",
    "        accordion = get_accordion(indexes, from_ind, to_ind)\n",
    "        run_widg = widgets.VBox([accordion, next_prev])\n",
    "        display(run_widg)\n",
    "\n",
    "def update_data(x):\n",
    "    global i\n",
    "    i = 0\n",
    "    top = filters.children[0].children[0].value\n",
    "    show_data(refresh=True, from_ind=i, to_ind=i+top, top=top)\n",
    "    \n",
    "def show_next(x):\n",
    "    global i\n",
    "    top = filters.children[0].children[0].value\n",
    "    i += top\n",
    "    i = min(max(0, i), len(indexes))\n",
    "    show_data(refresh=False, from_ind=i, to_ind=i+top, top=top)\n",
    "\n",
    "def show_prev(x):\n",
    "    global i\n",
    "    top = filters.children[0].children[0].value\n",
    "    i -= top\n",
    "    i = min(max(0, i), len(indexes))\n",
    "    show_data(refresh=False, from_ind=i, to_ind=i+top, top=top)\n",
    "\n",
    "def show_start(x):\n",
    "    global i\n",
    "    top = filters.children[0].children[0].value\n",
    "    i = 0\n",
    "    show_data(refresh=False, from_ind=i, to_ind=i+top, top=top)\n",
    "\n",
    "def show_end(x):\n",
    "    global i\n",
    "    top = filters.children[0].children[0].value\n",
    "    i = len(indexes) - top\n",
    "    show_data(refresh=False, from_ind=i, to_ind=i+top, top=top)\n",
    "    \n",
    "def get_filters():\n",
    "    \n",
    "    top_ = widgets.IntSlider(\n",
    "        value=10,\n",
    "        min=10,\n",
    "        max=100,\n",
    "        step=10,\n",
    "        description='Top:',\n",
    "        disabled=False,\n",
    "        continuous_update=False,\n",
    "        orientation='horizontal',\n",
    "        readout=True,\n",
    "        readout_format='d',\n",
    "#         layout = widgets.Layout(width='350px', height='20px')\n",
    "    )\n",
    "    \n",
    "    title = widgets.Combobox(\n",
    "            placeholder='Choose title',\n",
    "            options=tuple(np.append('All', get_filtered_df(df)['title'].unique())),\n",
    "            description='Title:',\n",
    "            ensure_option=True,\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "    location = widgets.Combobox(\n",
    "        placeholder='Choose locaction',\n",
    "        options=tuple(np.append('All', get_location(get_filtered_df(df)))),\n",
    "        description='Location:',\n",
    "        ensure_option=True,\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    company = widgets.Combobox(\n",
    "        placeholder='Choose locaction',\n",
    "        options=tuple(np.append('All', get_filtered_df(df)['company_name'].dropna().unique())),\n",
    "        description='Company:',\n",
    "        ensure_option=True,\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    find_words = widgets.Text(\n",
    "        value='',\n",
    "        placeholder='Type something',\n",
    "        description='Find words(;):',\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    sort_val = widgets.Dropdown(\n",
    "        value='model_score',\n",
    "        options=('random', 'model_score', 'date', 'location', 'title', 'salary'),\n",
    "        description='Sort by:',\n",
    "        ensure_option=True,\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    min_date = widgets.DatePicker(\n",
    "        description='Min Date',\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    salary = widgets.IntText(\n",
    "        value=0,\n",
    "        description='Min salary:',\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    color_features = widgets.Checkbox(value=True, description='Color features?')\n",
    "    retrain_model = widgets.Button(description='Retrain model', button_style='info')\n",
    "    apply_filters = widgets.Button(description='Apply filters/Refresh', button_style='info')\n",
    "    \n",
    "    return widgets.VBox([widgets.HBox([top_, sort_val, min_date]), \n",
    "                         widgets.HBox([title, location, company]),\n",
    "                         widgets.HBox([find_words, salary, color_features]), \n",
    "                         widgets.HBox([apply_filters, retrain_model])\n",
    "                        ], box_style='info')\n",
    "@contextmanager\n",
    "def show_loading():\n",
    "    filters.children[3].children[1].description = 'Running...'\n",
    "    filters.children[3].children[1].button_style = ''\n",
    "    yield\n",
    "    filters.children[3].children[1].description = 'Retrain model'\n",
    "    filters.children[3].children[1].button_style = 'info'\n",
    "    \n",
    "\n",
    "def retrain_model(x):\n",
    "    global model\n",
    "    global metric_message\n",
    "    with show_loading():\n",
    "        model = get_model(df, tf_idf)\n",
    "        update_data(x)\n",
    "    \n",
    "ind = get_filtered_df(df).index\n",
    "df.loc[ind, 'model_scores'] = model.predict_proba(tf_idf.transform(df.loc[ind, 'title'] + '\\n' + df.loc[ind, 'text']))[:,1]\n",
    "indexes = ind\n",
    "next_button = widgets.Button(description='Next', button_style='info')\n",
    "prev_button = widgets.Button(description='Previous', button_style='info')\n",
    "start_button = widgets.Button(description='Start', button_style='info')\n",
    "end_button = widgets.Button(description='End', button_style='info')\n",
    "\n",
    "next_prev = widgets.HBox([start_button, prev_button, next_button, end_button])\n",
    "filters = get_filters()\n",
    "\n",
    "display(filters)\n",
    "display(outs)\n",
    "\n",
    "next_prev.children[0].on_click(show_start)\n",
    "next_prev.children[1].on_click(show_prev)\n",
    "next_prev.children[2].on_click(show_next)\n",
    "next_prev.children[3].on_click(show_end)\n",
    "\n",
    "filters.children[3].children[0].on_click(update_data)\n",
    "filters.children[3].children[1].on_click(retrain_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1922cb24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top_fi = 30\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "names = tf_idf.get_feature_names_out()\n",
    "# result = pd.DataFrame([names, model.feature_importances_]).T\n",
    "result = pd.DataFrame([names, model.coef_[0]]).T\n",
    "result.columns=['names', 'feature_importance']\n",
    "result = result[abs(result['feature_importance']) >=\n",
    "                abs(result['feature_importance']).sort_values(ascending=False).iloc[top_fi]]\n",
    "sns.barplot(data=result.sort_values('feature_importance', ascending=False).head(top_fi),\n",
    "            y='names', x='feature_importance', ax=ax)\n",
    "plt.title('feature importance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419a4e44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
