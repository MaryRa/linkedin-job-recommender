{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f40b6040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import langid\n",
    "from random import shuffle\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import display\n",
    "from contextlib import contextmanager\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from src.model import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f69344a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/config.yaml\") as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "filename = cfg['vacancy-file']\n",
    "filename_out = cfg['vacancy-train-file']\n",
    "\n",
    "if filename in os.listdir('.'):\n",
    "    df = pd.read_csv(filename, index_col=0)\n",
    "else:\n",
    "    raise Exception(f'There is no file {filename}, run \"parse_data.py\" first')\n",
    "    sys.exit()\n",
    "\n",
    "df = df[~df['text'].isna()].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "df['salary_min'] = df['salary'].str.split('-').str[0].map(lambda x: ''.join(re.findall('\\d+', str(x).split(',')[0])))\n",
    "df.loc[df['salary'].isna(), 'salary_min'] = np.nan\n",
    "df['salary_min'] = df['salary_min'].astype(float)\n",
    "df['salary_max'] = df['salary'].str.split('-').str[1].map(lambda x: ''.join(re.findall('\\d+', str(x).split(',')[0])))\n",
    "df.loc[df['salary'].isna(), 'salary_max'] = np.nan\n",
    "df['salary_max'] = df['salary_max'].astype(float)\n",
    "\n",
    "df['salary_currency'] = df['salary'].str.split('-').str[0].map(\n",
    "    lambda x: ''.join(re.findall('[^(0-9,. )]', str(x).lower()))).replace('nan', '')\n",
    "\n",
    "currency_translation = {'':1, 'gbp': 1, 'usd': 0.79, 'sgd': 0.58, \n",
    "                        'jpy': 0.0055, 'mxn': 0.046, 'sek': 0.072, \n",
    "                        'eur': 0.86, 'cad': 0.59, 'aud': 0.52}\n",
    "currency_to_add = set(df['salary_currency']) - set(currency_translation.keys())\n",
    "if len(currency_to_add):\n",
    "    print(\"Add: \", currency_to_add)\n",
    "df['salary_max_gbp'] = df['salary_currency'].map(currency_translation) * df['salary_max']\n",
    "df['salary_min_gbp'] = df['salary_currency'].map(currency_translation) * df['salary_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62130f61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mary\\anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:313: UserWarning: After over-sampling, the number of samples (18506) in class 3 will be larger than the number of samples in the majority class (class #0 -> 9253)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mary\\anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:313: UserWarning: After over-sampling, the number of samples (18506) in class 4 will be larger than the number of samples in the majority class (class #0 -> 9253)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC (all): 0.97, (true): 0.92\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55270174f300472ab3e93b82228a29d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(box_style='info', children=(HBox(children=(IntSlider(value=10, continuous_update=False, description='Top:â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac719aa48e864b5ba45cb1ffcfaa982e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if filename_out in os.listdir('.'):\n",
    "    train = pd.read_csv(filename_out, index_col=0).reset_index(drop=True)\n",
    "    df = df[df.columns.difference(['dont_show', 'good', 'synthetic'])]\n",
    "    df = df.merge(train.loc[~((~train['synthetic'].isna()) & (train['synthetic'])), \n",
    "                            ['title','company_name','location', 'dont_show', 'good', 'synthetic']], \n",
    "                  on=['title','company_name','location'], how='left')\n",
    "    for col in set(df.columns) - set(train.columns):\n",
    "        train[col] = np.nan\n",
    "    df = pd.concat([df, train.loc[(~train['synthetic'].isna()) & (train['synthetic']), df.columns]])\n",
    "    df = df.reset_index(drop=True)\n",
    "else:\n",
    "    df['dont_show'] = np.nan\n",
    "    df['synthetic'] = np.nan\n",
    "    df['good'] = np.nan\n",
    "    \n",
    "    \n",
    "tf_idf = TfidfVectorizer(stop_words='english', max_df=0.99, min_df=0.01, norm='l1', ngram_range=(1,3))\n",
    "tf_idf.fit(df['title'] + '\\n' + df['text'])\n",
    "model = get_model(df, tf_idf)\n",
    "\n",
    "accordion = None\n",
    "indexes = None\n",
    "outs = widgets.Output()\n",
    "i = 0\n",
    "\n",
    "\n",
    "def calculate_palette(tf_idf, model):\n",
    "    names = tf_idf.get_feature_names_out()\n",
    "    result = pd.DataFrame([names, model.coef_[0]]).T\n",
    "    result.columns=['names', 'feature_importance']\n",
    "    result = result[abs(result['feature_importance'])>=abs(result['feature_importance']).sort_values().iloc[-30]]\n",
    "    cmap = sns.diverging_palette(20, 200, s=60, as_cmap=True)\n",
    "    norm = plt.Normalize(vmin=result['feature_importance'].min(), \n",
    "                         vmax=result['feature_importance'].max())\n",
    "    palette = {z: cmap(norm(h)) for h, z in zip(result['feature_importance'],result['names'])}\n",
    "    return palette\n",
    "\n",
    "def highlight_words(text, palette, pattern='(?u)\\\\b\\\\w\\\\w+\\\\b'):\n",
    "    key_words = [x for x in re.findall(pattern, text) if x.lower() in palette.keys()]\n",
    "    res = text\n",
    "    for w in key_words:\n",
    "        if w not in 'span style=\"background-color: rgba':\n",
    "            res = res.replace(w, \n",
    "                              f'<span style=\"background-color: rgba({palette[w.lower()][0]*255},{palette[w.lower()][1]*255},{palette[w.lower()][2]*255},1);\">{w}</span>')\n",
    "    return res\n",
    "\n",
    "def get_location(df):\n",
    "    locations = df['location'].dropna().drop_duplicates()\n",
    "    for i in np.arange(int(locations.str.split(',').str.len().max()-1), 0, step=-1):\n",
    "        locations = pd.concat([locations[locations.str.split(',').str.len() > i\n",
    "                                       ].str.split(',').str[-i:].str.join(',').drop_duplicates(), \n",
    "                               locations])\n",
    "    return locations.str.strip().unique()\n",
    "\n",
    "\n",
    "def get_widget_panel(df, i, palette=None):\n",
    "    text = ('<pre>\\n\\n</pre><b>' + df[\"title\"][i] + '</b>'+ \n",
    "            (('<pre>\\n' + df[\"salary\"][i] + '</pre>') if df[\"salary\"][i] is not np.nan else '') + \n",
    "            '<pre>\\n\\n' + df['text'][i] + '\\n\\n</pre>')\n",
    "    if palette is not None:\n",
    "        text = highlight_words(text, palette=palette)\n",
    "    link = f'<a href=\"{df[\"link\"][i]}\" target=\"_blank\">link to the vacancy</a>'\n",
    "    link = f'<p style=\"color:blue;\">{link}</p>'\n",
    "    vacancy = widgets.HTML(\n",
    "        value = link + text,\n",
    "        placeholder='',\n",
    "        description='',\n",
    "        layout = widgets.Layout(width='920px')\n",
    "    )\n",
    "\n",
    "    good_bad = widgets.Dropdown(\n",
    "        options=['good', 'bad'],\n",
    "        value=None,\n",
    "        rows=3,\n",
    "        description='Good or bad?',\n",
    "        disabled=False\n",
    "    )\n",
    "    why_good = widgets.Textarea(\n",
    "        placeholder='Type something',\n",
    "        description='good stuff',\n",
    "        disabled=False,\n",
    "        layout = widgets.Layout(width='920px', height='100px')\n",
    "\n",
    "    )\n",
    "    why_bad = widgets.Textarea(\n",
    "        placeholder='Type something',\n",
    "        description='bad stuff',\n",
    "        disabled=False,\n",
    "        layout = widgets.Layout(width='920px', height='100px')\n",
    "\n",
    "    )\n",
    "    show = widgets.Checkbox(\n",
    "        value=False,\n",
    "        description=\"Don't show it again (use only when you don't want to score)\",\n",
    "        disabled=False,\n",
    "        indent=False,\n",
    "        layout = widgets.Layout(width='920px', height='30px')\n",
    "    )\n",
    "    \n",
    "    widg = widgets.VBox([vacancy, good_bad, why_good, why_bad, show])\n",
    "    return widg\n",
    "\n",
    "\n",
    "def get_filtered_df(df):\n",
    "    return df[df['dont_show'].isna() & df['synthetic'].isna()]\n",
    "\n",
    "\n",
    "def get_relevant_df(df):\n",
    "    df_filt = get_filtered_df(df)\n",
    "    if filters.children[0].children[2].value:\n",
    "        df_filt = df_filt[df_filt['date'] >= str(filters.children[0].children[2].value)]\n",
    "    if filters.children[1].children[0].value and filters.children[1].children[0].value != 'All':\n",
    "        df_filt = df_filt[df_filt['title'].str.lower().str.find(filters.children[1].children[0].value.lower()) != -1]\n",
    "    if filters.children[1].children[1].value and filters.children[1].children[1].value != 'All':\n",
    "        df_filt = df_filt[df_filt['location'].str.lower().str.find(filters.children[1].children[1].value.lower()) != -1]\n",
    "    if filters.children[1].children[2].value and filters.children[1].children[2].value != 'All':\n",
    "        df_filt = df_filt[df_filt['company_name'] == filters.children[1].children[2].value]\n",
    "    if filters.children[2].children[1].value != 0:\n",
    "        df_filt = df_filt[df_filt['salary_max_gbp'] >= filters.children[2].children[1].value]\n",
    "    if filters.children[2].children[2].value and filters.children[2].children[2].value != 'All':\n",
    "        df_filt = df_filt[df_filt['language'] == filters.children[2].children[2].value]\n",
    "        \n",
    "    if filters.children[2].children[0].value != '':\n",
    "        words = [x.strip() for x in (filters.children[2].children[0].value).lower().split(';')]\n",
    "        ind = False\n",
    "        for w in words:\n",
    "            ind = ind | df_filt['text'].str.lower().str.find(w) != -1\n",
    "        df_filt = df_filt[ind]\n",
    "        \n",
    "    if df_filt.shape[0] == 0:\n",
    "        return [], widgets.Accordion(children=[], selected_index=None)\n",
    "    return df_filt\n",
    "\n",
    "def refresh_indexes(df):\n",
    "    df_filt = get_relevant_df(df)\n",
    "    if filters.children[0].children[1].value == 'model_score':\n",
    "        indexes = df_filt['model_scores'].sort_values(ascending=False).index\n",
    "    elif filters.children[0].children[1].value == 'random':\n",
    "        indexes = np.array(df_filt.index)\n",
    "        shuffle(indexes)\n",
    "    elif filters.children[0].children[1].value == 'date':\n",
    "        indexes = df_filt['date'].sort_values(ascending=False).index\n",
    "    elif filters.children[0].children[1].value == 'location':\n",
    "        indexes = df_filt['location'].sort_values().index\n",
    "    elif filters.children[0].children[1].value == 'title':\n",
    "        indexes = df_filt['title'].sort_values().index\n",
    "    elif filters.children[0].children[1].value == 'salary':\n",
    "        indexes = df_filt.sort_values('salary_max_gbp', ascending=False).index\n",
    "    return indexes\n",
    "    \n",
    "def get_accordion(indexes, from_ind, to_ind):\n",
    "    palette = None\n",
    "    inds = indexes[from_ind:to_ind]\n",
    "    if filters.children[3].children[0].value:\n",
    "        palette = calculate_palette(tf_idf, model)\n",
    "    accordion = widgets.Accordion(children=[get_widget_panel(df, ind, palette) for ind in inds], selected_index=None)\n",
    "    for k, ind in enumerate(inds):\n",
    "        accordion.set_title(k, str(df.loc[ind, 'title']) + '        ---   ' +\n",
    "                            str(df.loc[ind, 'company_name']) + ' --- ' +\n",
    "                            str(df.loc[ind, 'location']) + ' --- ' +\n",
    "                            str(df.loc[ind, 'date']) + \n",
    "                            f\" (model_score={df.loc[ind, 'model_scores']:.2f})\"\n",
    "                       )\n",
    "    return accordion\n",
    "\n",
    "def show_data(refresh, from_ind, to_ind, top):\n",
    "    global indexes\n",
    "    global accordion\n",
    "    global df\n",
    "    if accordion:\n",
    "        if refresh:\n",
    "            inds = indexes[from_ind:to_ind]\n",
    "        else:\n",
    "            inds = indexes[(from_ind-top):(to_ind-top)]\n",
    "        for k, ind in enumerate(inds):\n",
    "            if accordion.children[k].children[4].value:\n",
    "                df.loc[ind, 'dont_show'] = accordion.children[k].children[4].value\n",
    "            if accordion.children[k].children[1].value is not None:\n",
    "                df.loc[ind, 'good'] = (accordion.children[k].children[1].value == 'good') * 1\n",
    "                df.loc[ind, 'dont_show'] = True\n",
    "            for is_good, text_highlight in enumerate([\n",
    "                accordion.children[k].children[3].value, \n",
    "                accordion.children[k].children[2].value]):\n",
    "                if text_highlight != '':\n",
    "                    max_ind = int(df.index.max() + 1)\n",
    "                    df.loc[max_ind, :] = df.loc[ind, :]\n",
    "                    df.loc[max_ind, 'text'] = text_highlight\n",
    "                    df.loc[max_ind, 'synthetic'] = True\n",
    "                    df.loc[max_ind, 'date'] = str(datetime.datetime.now().date())\n",
    "                    df.loc[max_ind, 'good'] = is_good\n",
    "                    df.loc[ind, 'dont_show'] = True\n",
    "                df[(~df['good'].isna()) | (~df['dont_show'].isna())].reset_index(drop=True).to_csv(filename_out)\n",
    "    \n",
    "    with outs:\n",
    "        clear_output()\n",
    "        if refresh:\n",
    "            indexes = refresh_indexes(df)\n",
    "        accordion = get_accordion(indexes, from_ind, to_ind)\n",
    "        run_widg = widgets.VBox([accordion, next_prev])\n",
    "        display(run_widg)\n",
    "\n",
    "def update_data(x):\n",
    "    global i\n",
    "    i = 0\n",
    "    top = filters.children[0].children[0].value\n",
    "    show_data(refresh=True, from_ind=i, to_ind=i+top, top=top)\n",
    "    \n",
    "def show_next(x):\n",
    "    global i\n",
    "    top = filters.children[0].children[0].value\n",
    "    i += top\n",
    "    i = min(max(0, i), len(indexes))\n",
    "    show_data(refresh=False, from_ind=i, to_ind=i+top, top=top)\n",
    "\n",
    "def show_prev(x):\n",
    "    global i\n",
    "    top = filters.children[0].children[0].value\n",
    "    i -= top\n",
    "    i = min(max(0, i), len(indexes))\n",
    "    show_data(refresh=False, from_ind=i, to_ind=i+top, top=top)\n",
    "\n",
    "def show_start(x):\n",
    "    global i\n",
    "    top = filters.children[0].children[0].value\n",
    "    i = 0\n",
    "    show_data(refresh=False, from_ind=i, to_ind=i+top, top=top)\n",
    "\n",
    "def show_end(x):\n",
    "    global i\n",
    "    top = filters.children[0].children[0].value\n",
    "    i = len(indexes) - top\n",
    "    show_data(refresh=False, from_ind=i, to_ind=i+top, top=top)\n",
    "    \n",
    "def get_filters():\n",
    "    \n",
    "    top_ = widgets.IntSlider(\n",
    "        value=10,\n",
    "        min=10,\n",
    "        max=100,\n",
    "        step=10,\n",
    "        description='Top:',\n",
    "        disabled=False,\n",
    "        continuous_update=False,\n",
    "        orientation='horizontal',\n",
    "        readout=True,\n",
    "        readout_format='d',\n",
    "#         layout = widgets.Layout(width='350px', height='20px')\n",
    "    )\n",
    "    \n",
    "    title = widgets.Combobox(\n",
    "            placeholder='Choose title',\n",
    "            options=tuple(np.append('All', get_filtered_df(df)['title'].unique())),\n",
    "            description='Title:',\n",
    "            ensure_option=True,\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "    location = widgets.Combobox(\n",
    "        placeholder='Choose locaction',\n",
    "        options=tuple(np.append('All', get_location(get_filtered_df(df)))),\n",
    "        description='Location:',\n",
    "        ensure_option=True,\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    company = widgets.Combobox(\n",
    "        placeholder='Choose locaction',\n",
    "        options=tuple(np.append('All', get_filtered_df(df)['company_name'].dropna().unique())),\n",
    "        description='Company:',\n",
    "        ensure_option=True,\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    find_words = widgets.Text(\n",
    "        value='',\n",
    "        placeholder='Type something',\n",
    "        description='Find words(;):',\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    sort_val = widgets.Dropdown(\n",
    "        value='model_score',\n",
    "        options=('random', 'model_score', 'date', 'location', 'title', 'salary'),\n",
    "        description='Sort by:',\n",
    "        ensure_option=True,\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    min_date = widgets.DatePicker(\n",
    "        description='Min Date',\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    salary = widgets.IntText(\n",
    "        value=0,\n",
    "        description='Min salary:',\n",
    "        disabled=False\n",
    "    )\n",
    "    language = widgets.Dropdown(\n",
    "        value='en',\n",
    "        options=tuple(np.append('All', get_filtered_df(df)['language'].dropna().unique())),\n",
    "        description='Language:',\n",
    "        ensure_option=True,\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    color_features = widgets.Checkbox(value=True, description='Color features?')\n",
    "    retrain_model = widgets.Button(description='Retrain model', button_style='info')\n",
    "    apply_filters = widgets.Button(description='Apply filters/Refresh', button_style='info')\n",
    "    \n",
    "    return widgets.VBox([widgets.HBox([top_, sort_val, min_date]), \n",
    "                         widgets.HBox([title, location, company]),\n",
    "                         widgets.HBox([find_words, salary, language]), \n",
    "                         widgets.HBox([color_features]), \n",
    "                         widgets.HBox([apply_filters, retrain_model])\n",
    "                        ], box_style='info')\n",
    "@contextmanager\n",
    "def show_loading():\n",
    "    filters.children[4].children[1].description = 'Running...'\n",
    "    filters.children[4].children[1].button_style = ''\n",
    "    yield\n",
    "    filters.children[4].children[1].description = 'Retrain model'\n",
    "    filters.children[4].children[1].button_style = 'info'\n",
    "    \n",
    "\n",
    "def retrain_model(x):\n",
    "    global model\n",
    "    global metric_message\n",
    "    with show_loading():\n",
    "        model = get_model(df, tf_idf)\n",
    "        update_data(x)\n",
    "    \n",
    "ind = get_filtered_df(df).index\n",
    "df.loc[ind, 'model_scores'] = model.predict_proba(tf_idf.transform(df.loc[ind, 'title'] + '\\n' + df.loc[ind, 'text']))[:,1]\n",
    "indexes = ind\n",
    "next_button = widgets.Button(description='Next', button_style='info')\n",
    "prev_button = widgets.Button(description='Previous', button_style='info')\n",
    "start_button = widgets.Button(description='Start', button_style='info')\n",
    "end_button = widgets.Button(description='End', button_style='info')\n",
    "\n",
    "next_prev = widgets.HBox([start_button, prev_button, next_button, end_button])\n",
    "filters = get_filters()\n",
    "\n",
    "display(filters)\n",
    "display(outs)\n",
    "\n",
    "next_prev.children[0].on_click(show_start)\n",
    "next_prev.children[1].on_click(show_prev)\n",
    "next_prev.children[2].on_click(show_next)\n",
    "next_prev.children[3].on_click(show_end)\n",
    "\n",
    "filters.children[4].children[0].on_click(update_data)\n",
    "filters.children[4].children[1].on_click(retrain_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fda140d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
